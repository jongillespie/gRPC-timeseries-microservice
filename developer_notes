Jon's 'in-motion' Developer Notes
---------------------------------
Purpose: to document development, links to resources, and provide insight into Jon's process.

- Started with what I did not recognise: gRPC
    - Watched a few intro videos
    - Read the docs.
        gRPC
        - Google uses internally as well as externally for pub/sub
        - Netflix
        - Square (contributor and used to replace their APIs)
        - CoreOS
        - CockroachDB
        ‘Future’ of micro-services API, mobile-server API, and maybe web APIs
        RPC = Remote Procedure Call
        Allows a client to make a server call and it syntactically appears to be direct 
        - Define the messages and services using ‘Protocol Buffers’
            - Protocol Buffers are language agnostic, efficient for small payloads, convenient for transporting a lot of data and allows easy evolution of API with rules.
        .proto file is the protocol configuration file

- Inspected the data
    - Noticed a NaN

- Drew a mind-map of elements, languages and frameworks expected

- Asked about the final product desired via email (UI and Data Presentation)

- Created a GitHub Repo

- Set up local dev env - inc. venv.

-------
- Rough Plan:
    - Python / Pandas to clean CSV on server side. 
    - Implement Timescale
        - Insert clean data
        - Create first query: return all data.
    - Create Flask Server (dev)
    - Implement gRPC Server side
    - Implement gRPC Client within Flask Server
    - Implement Return all data over gRPC
    - Create GET Route on Flask Server - connecting to gRPC method
    - Test GET route with Postman
    - Create basic HTML page to display all data.
    ** Test each element along the way
    ** Utilise Branching Model where appropriate

    ** Some new things here, so start simple, don't over-engineer - do write clean minimal code.
       Revisit containerisation following POC

    Beyond POC 
    >> Implement additional data queries / manipulation
    >> Enhance UI
    >> Docker Image?

-------
- Used Pandas to clean the data, removed all NaN, convert data types to float and timestamp from str.

- Install TimeScale on MacOS, https://docs.timescale.com/latest/getting-started
    # Add our tap
    brew tap timescale/tap

    # To install
    brew install timescaledb

    # Post-install to move files to appropriate place
    /usr/local/bin/timescaledb_move.sh

    timescaledb-tune
    timescaledb_move.sh

    # Restart PostgreSQL instance
    brew services restart postgresql

    # Add a superuser postgres:
    createuser postgres -s

    # Connect to PostgreSQL, using a superuser named 'postgres'
    psql -U postgres -h localhost

    -- Create the database
    CREATE database meterusage;

    -- Connect to the database
    \c meterusage

    -- Extend the database with TimescaleDB
    CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;

    *** Connect to the new database ***
    psql -U postgres -h localhost -d meterusage

>> grpc_server.py & clean_csv_data.py
- Python TimeScale QuickStart Offical Tutorial https://docs.timescale.com/latest/tutorials/quickstart-python
- Install psycopg2 : Psycopg is the most popular PostgreSQL database adapter for the Python programming language. https://pypi.org/project/psycopg2/
    pip install psycopg2-binary

    - Create a HyperTable (from Scratch) https://docs.timescale.com/latest/getting-started/creating-hypertables
    - To create a hypertable, you start with a regular SQL table, and then convert it into a hypertable via the function create_hypertable.
    - Implemented in Code...

- Inserterd the cleaned dataframe into the db table with pandas.to_sql: https://pythontic.com/pandas/serialization/postgresql
    - Using SQLAlchemy: https://docs.sqlalchemy.org/en/13/core/engines.html#postgresql
- Confirmed correct datatypes are saved and data is in created table
- Created a get all query
- Enhanced the execution tool to faciliatate single or multiple queries

>> focus: grpc
- An introduction to gRPC and protocol buffers. https://grpc.io/docs/what-is-grpc/introduction/
- A client application can directly call a method on a server application on a different machine as if it were a local object
- gRPC uses Protocol Buffers, Google’s mature open source mechanism for serializing structured data (although it can be used with other data formats such as JSON).
- the idea of defining a service, specifying the methods that can be called remotely with their parameters and return types.
* - 4 Service types
      - Unary RPCs                  eg: rpc SayHello(HelloRequest) returns (HelloResponse);
      - Server Streaming                rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse);
      - Client Streaming                rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse);
      - Bi-directional Streaming        rpc BidiHello(stream HelloRequest) returns (stream HelloResponse);
- gRPC programming API in most languages comes in both synchronous and asynchronous flavors.
- With gRPC we can define our service once in a .proto file and generate clients and servers

- Install gRPC 

    pip install grpcio
    pip install grpcio-tools

    To generate the files from the proto::: tested and works - correct paths.
      > python -m grpc_tools.protoc --proto_path=. --python_out=. --grpc_python_out=. meterusage.proto

- Protocol Buffers Language Guide (proto3): https://developers.google.com/protocol-buffers/docs/proto3
- Simple request response gRPC implemented utilising one of their examples: https://github.com/grpc/grpc/tree/master/examples/python/data_transmission
- Proto upgraded to Server Stream - will send each timeseries entry within it
- Changed values of Response method to protobuf's timestamp and a float
- Conversion between datetime and timestamps important
- Tested the server and client - client reconverts and can display meterusage entries

* > Dates are incorrect - showing as 1970... format/type conversion issue. REVISIT as BUG FIX

>> focus: frontend
- Implemented a simple Flask app, however, running the flask app and importing the stub raises:

    Error: While importing "app", an ImportError was raised:

    Traceback (most recent call last):
      File "/Users/jongillespie/.pyenv/versions/3.8.2/lib/python3.8/site-packages/flask/cli.py", line 240, in locate_app
        __import__(module_name)
      File "/Users/jongillespie/Documents/01_Code_Bases/gRPC-timeseries-microservice/grpc_client_flask_server/app.py", line 3, in <module>
        import grpc_stub
      File "/Users/jongillespie/Documents/01_Code_Bases/gRPC-timeseries-microservice/grpc_client_flask_server/grpc_stub.py", line 17, in <module>
        import grpc
    ModuleNotFoundError: No module named 'grpc'

* > Something is wrong... the above is a symptom of a bigger issue...

https://github.com/grpc/grpc/issues/4629

    With #14561 in, you should now be able to use gevent.

    Note that you have to explicitly monkey patch Python, as well as enabling the gevent loop for Python (Before doing anything with gRPC)

    from gevent import monkey
    monkey.patch_all()

    import grpc.experimental.gevent as grpc_gevent
    grpc_gevent.init_gevent()
    This will be included in the 1.11 release.

    I'm closing this master issue, and separate issues can be created with any issues encountered using gevent.

>> Discovered Gevent should work with gRPC: https://github.com/kragniz/python-etcd3/issues/388
*> However, gevent refuses to import even though installed... unknown issue. All versions confirmed corrrect.

- Decided to try using Django (for the first time...)
- Built a simple Django app and am having issues with how modules are imported.
- 'Hacked' some solution together but does not feel right.
  - Seems to work though, got further, but error now is: "ValueError: Cannot invoke RPC: Channel closed!"
- Had to change my stub method a bit... but still doesn't feel right.

- Found an article about making gRPC work with Django... this is interesting:
    http://flagzeta.org/blog/using-grpc-with-django/
        Next step is to focus on integration with the server. Django is a WSGI application, which is normally run by a WSGI HTTP server like Gunicorn or uWSGI. Both Gunicorn and uWSGI have their own event loop, which are clashing with the GRPC event loop.
        Gevent may be used here to make the two cooperate, but I am reluctant to explore that path. The more complex your Django (or GRPC) stack becomes the easier is to find a piece of software that is not gevent-friendly. Also, I am not a fan of its approach.
        I am choosing a way that is a lot simpler and more basic: have two separate processes, with two event loops. In order to do that, they must be independent. They will listen to different ports, and they will have separate lifecycles (startup/shutdown/etc).
        What we need is a Django management command that instead of entering the WSGI loop, enters in the GRPC loop.

- YESSSSS!!! The articel gave me a new idea...
- Amended the stub to be a callable method with the channel as a param.
- It works :) the module imports are likely anti-pattern.... so need to ask ADVICE on this.
- Stub also now doesn't convert to JSON, instead, provides the str so that Django can serve as JSONResponse.

- Now to fix the BUG as above... timestamp issue.

- BUG FIXED!!!!! Annnnd Done :)
- Now, polish up any files missing notes... """ """
- Create simple README based on the above...

- Push and Email Client.



























TIMESCALE INSTALL CLI Records for reference >> use later for Docker build?:
==> timescaledb
RECOMMENDED: Run 'timescaledb-tune' to update your config settings for TimescaleDB.

  timescaledb-tune --quiet --yes

IF NOT, you'll need to make sure to update /usr/local/var/postgres/postgresql.conf
to include the extension:

  shared_preload_libraries = 'timescaledb'

To finish the installation, you will need to run:

  timescaledb_move.sh

If PostgreSQL is installed via Homebrew, restart it:

  brew services restart postgresql

Moving files into place...
Success.
 jongillespie@jg-mbp  ~  timescaledb-tune                                                                                                                                                   ✔  841  16:03:18
Using postgresql.conf at this path:
/usr/local/var/postgres/postgresql.conf

Is this correct? [(y)es/(n)o]: y
Writing backup to:
/var/folders/21/ntgjmpl10jd6rzpzy_2z3m580000gn/T/timescaledb_tune.backup202008071604

shared_preload_libraries needs to be updated
Current:
#shared_preload_libraries = ''
Recommended:
shared_preload_libraries = 'timescaledb'
Is this okay? [(y)es/(n)o]: y
success: shared_preload_libraries will be updated

Tune memory/parallelism/WAL and other settings? [(y)es/(n)o]: n
Saving changes to: /usr/local/var/postgres/postgresql.conf